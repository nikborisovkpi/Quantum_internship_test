# Task 1. Natural Language Processing. Named entity recognition

### Repository structure:
1) Dataset_notebook.ipynb - notebook that explains the process of the dataset creation. The main parts of notebook:
   - generate_synthetic_data - func for generating data to split it on train and validation sets. Data are generated by list of mountains and templates of sentances that randomly insert mountain names
   - mountains - list of some popular mountains for data generation
   - sentences_templates - templates for data generation, generate_synthetic_data 
   - save_synthetic_data - func for saving ganerated train and validation datasets to the text files. 

2) ner_train.py - python script (.py) for model training. The main parts of file:
   - class NERDataset() - A class for preparing a dataset for training the NER model.
    Converts text to tokens, aligns labels to tokens, and returns a dictionary containing the input data for the model. Used for passing data to the Trainer.
   - load_synthetic_data - function that loads texts and tags from a file, where each line contains a word and its tag, and an empty line is a sentence separator.
   - compute_metrics - function that helps calculate key metrics for assessing the quality of model training: precision, recall and f1.
   - main() - main func start model training: loads the tokenizer and model, creates datasets and data_collator, sets training parameters (TrainingArguments), runs training via Trainer,saves the trained model and tokenizer.

3) ner_inference.py - python script (.py) for model inference. The main parts of file:
   - extract_mountains - load model and tokenizer from model_dir path to extract mountain names list from selected sentence. 
   - main() - main func use extract_mountains to find all mountain names and print them as list.

4)  Demo_notebook.ipynb - Jupyter notebook with demo. Uses all functions and methods from ner_train.py and ner_inference.py to train NER model(ner_model_train) on generated dataset from text files and use it to extract mountains names from selected sentence.

5) train_data.txt and val_data.txt - text files with train and validation datasets which were generated in Dataset_notebook.



### Usage example:
First, let's navigate to the Task1 folder:
```
cd Task1
```

Now you need to install all packages from requirements file:
```
pip install -r requirements.txt
```

To train the NER model:
```
python ner_train.py --epochs 3 --batch_size 32 --output_dir ./ner_model  
```

To use the trained NER model:
```
python ner_inference.py --model_dir ./ner_model --text "The Everest is the highest mountain."
```